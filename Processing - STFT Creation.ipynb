{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec73c668-6f3b-4574-9d58-bbc083bffe34",
   "metadata": {},
   "source": [
    "# STFT Denoising\n",
    "This is a jupyter notebook for processing of waveform data in the time-domain into STFT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af13b8-49e5-4d87-99d9-31f5d4d1457c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 19:26:57.061335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import stft, istft\n",
    "\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889c32f-e480-4ff4-9c25-97fb919bba8b",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load the data from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674b7ed7-dc09-4409-92ab-9f443854f2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"./data/high_snr_25/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c3047f6-ee19-4b73-a75a-1c8ad1457d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveforms = np.load(folder + \"waveforms.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e2031c-fa97-4b64-a224-bc3e5af045ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_signal = waveforms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562c6a0d-7d62-4ea2-b883-9f750254d16d",
   "metadata": {},
   "source": [
    "### Already processed training data\n",
    "This training data already contains (noisy) input and (denoised) target set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7976521-ff10-4860-a02f-27f9b90087da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# following the tensorflow load_data tutorial\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "# doesn't really work because it is not in numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d9c5bec-3b63-48ff-a39a-03dbaa0ed36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"/home/alex/Desktop/Promotion/Code/Jupyter-Lab Notebooks/Waveform Denoiser/denoise_training_real/third dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920db207-1def-4e40-9f7b-7f13521e81fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pure_test = np.load (folder + 'pure_test_set.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe65786d-8e79-4e75-8f85-77b9b8c6d7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "if loading:\n",
    "    pure_training = np.load(folder + \"pure_training_set.npy\")\n",
    "    pure_test = np.load (folder + 'pure_test_set.npy')\n",
    "    noisy_training = np.load(folder + 'noisy_training_set.npy')\n",
    "    noisy_test = np.load(folder + 'noisy_test_set.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5f103-209e-4f28-bd8c-2a04d270f8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STFT\n",
    "Short term fourier transform of a test signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78539321-f206-42f4-8fed-4e7f56b36b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,t, result_stft = stft(test_signal, fs =1/5.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6a30d70-eb10-432c-8664-49e7e3eeb65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stfts = []\n",
    "for waveform in waveforms:\n",
    "    f,t, result_stft = stft(waveform, fs =1/5.)\n",
    "    stfts.append(result_stft)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51684ff0-e36c-4250-8791-d7c32df93bd8",
   "metadata": {},
   "source": [
    "## Using tensorflow dataset\n",
    "Tensorflows dataset class can built data from the numpy arrays of the already created noisy and pure test sets.\n",
    "\n",
    "It just needs to be reprocessed.\n",
    "\n",
    "See here:\n",
    "\n",
    "This tutorial is directly applicable to my case here\n",
    "https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "It shows how I can load numpy arrays and create a dataset from it.\n",
    "Does the dataset object need to be batched?\n",
    "\n",
    "\n",
    "More general information can be found here\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "The last link was initially found at\n",
    "https://cs230.stanford.edu/blog/datapipeline/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba0c8d-d23a-4782-83a8-1adc8b7430aa",
   "metadata": {},
   "source": [
    "# need to understand what dataset batching does..\n",
    "Batching is a necessary step in the numpy load tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b09f32-d02c-4e0b-b798-595adc84338b",
   "metadata": {},
   "source": [
    "## Processing: complex phase and amplitude split\n",
    "The result of a STFT are complex data. They need to be split into separate amplitude and phase arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3bc992e-5672-4527-95ee-09e80c825737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StftDataset(object):\n",
    "    def __init__(self, data=None, fs = 1./5.):\n",
    "        \"\"\" initialize\n",
    "        \"\"\"\n",
    "        self.data = None\n",
    "        if data is not None:\n",
    "            self.process_data(data, fs=fs)\n",
    "            \n",
    "    def process_data(self, data, fs=1./5.):\n",
    "        \n",
    "        # process the data\n",
    "        stfts = []\n",
    "        for waveform in tqdm(data):\n",
    "            f,t, result_stft = stft(waveform, fs = fs)\n",
    "            stfts.append(result_stft)\n",
    "            \n",
    "        # store the axis parameters of the STFT (times and frequencies)\n",
    "        self.f = f\n",
    "        self.t = t\n",
    "\n",
    "        # store the parameters of the \n",
    "        n = len(stfts)\n",
    "        number_frequencies = stfts[0].shape[0]\n",
    "        number_timeslices = stfts[0].shape[1]\n",
    "\n",
    "        empty_data = np.zeros((n, number_frequencies, number_timeslices, 2))\n",
    "\n",
    "        for count, current_stft in enumerate(stfts):\n",
    "            amp = np.absolute(current_stft)\n",
    "            phase = np.angle(current_stft)\n",
    "            empty_data[count, :,:, 0] = amp\n",
    "            empty_data[count, :,:, 1] = phase\n",
    "\n",
    "        self.data = empty_data\n",
    "\n",
    "    def save(self, folder, name):\n",
    "        \"\"\" This methods saves the data under the name\n",
    "        in the given folder\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if data is actually available\n",
    "        if self.data is None:\n",
    "            print(\"No data stored yet.\")\n",
    "            return\n",
    "        \n",
    "        # create correct paths relative to the OS\n",
    "        t_path = os.path.join(folder, name + \"_t\")\n",
    "        f_path = os.path.join(folder, name + \"_f\")\n",
    "        name_path = os.path.join(folder, name)\n",
    "        \n",
    "        # make a new folder if it already exists\n",
    "        try: \n",
    "            os.mkdir(folder)\n",
    "            print(\"Creating new folder...\")\n",
    "        except FileExistsError:\n",
    "            print(\"Writing into existing folder...\")\n",
    "        \n",
    "        # store the data\n",
    "        np.save(t_path, self.t)\n",
    "        np.save(f_path, self.f)\n",
    "        np.save(name_path, self.data)\n",
    "        \n",
    "    def load(self, folder, name):\n",
    "        \"\"\" This method loads the stored data (name) in \n",
    "        the given folder\n",
    "        \"\"\"\n",
    "        # check if folder exists\n",
    "        try:\n",
    "            os.listdir(folder)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Folder does not exist: {folder}\")\n",
    "            return\n",
    "\n",
    "        # create correct paths relative to the OS\n",
    "        t_path = os.path.join(folder, name + \"_t.npy\")\n",
    "        f_path = os.path.join(folder, name + \"_f.npy\")\n",
    "        name_path = os.path.join(folder, name +\".npy\")\n",
    "        \n",
    "        try:\n",
    "            # load the data\n",
    "            t = np.load(t_path)\n",
    "            f = np.load(f_path)\n",
    "            stfs = np.load(name_path)\n",
    "            print(\"Files loaded.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Error: Files do not exist.\")\n",
    "            return\n",
    "        \n",
    "        self.t = t\n",
    "        self.f = f\n",
    "        self.data = stfs\n",
    "            \n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7c00c44-2f99-4256-8953-2f9f73f42531",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSetBuilder(object):\n",
    "    \"\"\" This class takes the base (the noisy examples) and\n",
    "    the target (the denoised set) data in the time domain\n",
    "    and converts it into a tensorflow dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, base, target):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "714870c8-d743-40b6-be65-dec5427b3d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"training/small training set\"\n",
    "base = \"noisy_small\"\n",
    "target = \"pure_small\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd7ffec0-3658-4e7d-b7de-00c6023ea6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded.\n",
      "Files loaded.\n"
     ]
    }
   ],
   "source": [
    "noisy_stft = StftDataset()\n",
    "pure_stft = StftDataset()\n",
    "\n",
    "noisy_stft.load(folder, base)\n",
    "pure_stft.load(folder, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e302288-e06d-42c0-925d-c45e21bdcd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
