{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec73c668-6f3b-4574-9d58-bbc083bffe34",
   "metadata": {},
   "source": [
    "# STFT Denoising\n",
    "This is a jupyter notebook for processing of waveform data in the time-domain into STFT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49af13b8-49e5-4d87-99d9-31f5d4d1457c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 12:37:53.917605: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import stft, istft\n",
    "\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889c32f-e480-4ff4-9c25-97fb919bba8b",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load the data from the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674b7ed7-dc09-4409-92ab-9f443854f2ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"./data/high_snr_25/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3047f6-ee19-4b73-a75a-1c8ad1457d64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "waveforms = np.load(folder + \"waveforms.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e2031c-fa97-4b64-a224-bc3e5af045ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_signal = waveforms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab5f103-209e-4f28-bd8c-2a04d270f8d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STFT\n",
    "Short term fourier transform of a test signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78539321-f206-42f4-8fed-4e7f56b36b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f,t, result_stft = stft(test_signal, fs =1/5.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a30d70-eb10-432c-8664-49e7e3eeb65f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stfts = []\n",
    "for waveform in waveforms:\n",
    "    f,t, result_stft = stft(waveform, fs =1/5.)\n",
    "    stfts.append(result_stft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5126b7c9-9ee2-46ab-8491-e59a4ea5c0a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stfts[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb93706f-e249-4ebc-9f4d-7908147c70db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68d240a0-9235-4ba4-9303-97000fd9963e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_data = np.zeros((len(stfts), stfts[1].shape[0], stfts[1].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5c27af9-fe07-4fd4-a875-b508b1875182",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 129, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cfbc00f-8cdc-46db-875a-c2a143a0124c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12755/3145602325.py:1: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  empty_data[0] = stfts[1]\n"
     ]
    }
   ],
   "source": [
    "empty_data[0] = stfts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51684ff0-e36c-4250-8791-d7c32df93bd8",
   "metadata": {},
   "source": [
    "## Using tensorflow dataset\n",
    "Tensorflows dataset class can built data from the numpy arrays of the already created noisy and pure test sets.\n",
    "\n",
    "It just needs to be reprocessed.\n",
    "\n",
    "See here:\n",
    "\n",
    "This tutorial is directly applicable to my case here\n",
    "https://www.tensorflow.org/tutorials/load_data/numpy\n",
    "It shows how I can load numpy arrays and create a dataset from it.\n",
    "Does the dataset object need to be batched?\n",
    "\n",
    "\n",
    "More general information can be found here\n",
    "https://www.tensorflow.org/guide/data\n",
    "\n",
    "The last link was initially found at\n",
    "https://cs230.stanford.edu/blog/datapipeline/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7976521-ff10-4860-a02f-27f9b90087da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# following the tensorflow load_data tutorial\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
    "\n",
    "# doesn't really work because it is not in numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d9c5bec-3b63-48ff-a39a-03dbaa0ed36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"/home/alex/Desktop/Promotion/Code/Jupyter-Lab Notebooks/Waveform Denoiser/denoise_training_real/third dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "204b55ce-c803-4933-a1b7-583c46e465ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pure_training_set.npy',\n",
       " 'pure_test_set.npy',\n",
       " 'noisy_training_set.npy',\n",
       " 'noisy_test_set.npy',\n",
       " 'notes']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe65786d-8e79-4e75-8f85-77b9b8c6d7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loading = False\n",
    "\n",
    "if loading:\n",
    "    pure_training = np.load(folder + \"pure_training_set.npy\")\n",
    "    pure_test = np.load (folder + 'pure_test_set.npy')\n",
    "    noisy_training = np.load(folder + 'noisy_training_set.npy')\n",
    "    noisy_test = np.load(folder + 'noisy_test_set.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ba0c8d-d23a-4782-83a8-1adc8b7430aa",
   "metadata": {},
   "source": [
    "# need to understand what dataset does.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509df05-7bce-4443-95ce-fe5bbc2c10fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
