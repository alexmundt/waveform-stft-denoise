{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d038a39-333d-466f-813b-ba25e46aaf08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 10:42:14.206020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft, istft\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact\n",
    "from code.stftprocessing import StftDataset\n",
    "from code.dsvisual import DatasetVisualizer\n",
    "from tqdm import tqdm\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c5005d7-ef4c-4d6f-ac61-9022a8267d18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folder = \"training/new_small\"\n",
    "# base = \"noisy_small\"\n",
    "# target = \"pure_small\"\n",
    "\n",
    "folder = \"training/original training\"\n",
    "base = \"noisy\"\n",
    "target = \"pure\"\n",
    "\n",
    "test_folder = \"training/test set\"\n",
    "test_base = \"noisy_test\"\n",
    "test_target = \"pure_test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a3f1e0-0fa2-4d50-8552-5575b1bc0f3d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files loaded.\n",
      "Files loaded.\n",
      "Files loaded.\n",
      "Files loaded.\n"
     ]
    }
   ],
   "source": [
    "noisy_stft = StftDataset()\n",
    "pure_stft = StftDataset()\n",
    "\n",
    "noisy_stft.load(folder, base)\n",
    "pure_stft.load(folder, target)\n",
    "\n",
    "# test sets\n",
    "noisy_test_stft = StftDataset()\n",
    "pure_test_stft = StftDataset()\n",
    "noisy_test_stft.load(test_folder, test_base)\n",
    "pure_test_stft.load(test_folder, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11608d20-dfe1-4179-9d4c-6dd7b94af13e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(430848, 129, 9, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_stft.get_data().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc006258-5af8-42b3-ab54-a4189c550ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 10:44:28.706197: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-03-29 10:44:28.783853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-03-29 10:44:28.846667: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:28.854492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 970 computeCapability: 5.2\n",
      "coreClock: 1.253GHz coreCount: 13 deviceMemorySize: 3.93GiB deviceMemoryBandwidth: 208.91GiB/s\n",
      "2023-03-29 10:44:28.854542: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-29 10:44:29.056503: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-29 10:44:29.056649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-03-29 10:44:29.171867: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-29 10:44:29.230884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-29 10:44:29.445094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-03-29 10:44:29.487307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-03-29 10:44:29.871202: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-03-29 10:44:29.871474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:29.871781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:29.871970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-03-29 10:44:30.013741: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-29 10:44:30.019688: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-03-29 10:44:30.019969: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:30.020231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:04:00.0 name: NVIDIA GeForce GTX 970 computeCapability: 5.2\n",
      "coreClock: 1.253GHz coreCount: 13 deviceMemorySize: 3.93GiB deviceMemoryBandwidth: 208.91GiB/s\n",
      "2023-03-29 10:44:30.020279: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-29 10:44:30.020305: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-03-29 10:44:30.020324: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-03-29 10:44:30.020342: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-03-29 10:44:30.020360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-03-29 10:44:30.020378: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-03-29 10:44:30.020395: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-03-29 10:44:30.020413: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-03-29 10:44:30.020504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:30.020782: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:30.020979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-03-29 10:44:30.028481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-03-29 10:44:34.090872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-03-29 10:44:34.090900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-03-29 10:44:34.090907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-03-29 10:44:34.112034: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:34.112290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:34.112506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-29 10:44:34.112702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2928 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 970, pci bus id: 0000:04:00.0, compute capability: 5.2)\n",
      "2023-03-29 10:44:37.622933: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4001716224 exceeds 10% of free system memory.\n",
      "2023-03-29 10:45:18.509521: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 4001716224 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# get the amplitudes of training and test sets\n",
    "examples = noisy_stft.get_data()[:,:,:,0]\n",
    "labels = pure_stft.get_data()[:,:,:,0]\n",
    "\n",
    "stride_reduce = 100\n",
    "examples_test = noisy_test_stft.get_data()[::stride_reduce,:,:,0]\n",
    "labels_test = pure_test_stft.get_data()[::stride_reduce,:,:,0]\n",
    "\n",
    "examples_test_phase = noisy_test_stft.get_data()[::stride_reduce,:,:,1]\n",
    "labels_test_phase = pure_test_stft.get_data()[::stride_reduce,:,:,1]\n",
    "\n",
    "# build the dataset from tensorflow functions\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((examples, labels))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((examples_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6562c220-7860-4297-a77d-c5e88007007a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: ((129, 9), (129, 9)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee2fe844-0bdc-4a91-b427-ce5ed1576742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (129, 9 , 2)\n",
    "input_shape = (129, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6f06e8-d6e8-41fc-8bb3-9038794e20b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "SHUFFLE_BUFFER_SIZE = 2000\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97c703f4-8424-435f-a5a8-c7b3a34c593a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_rate = 0.2\n",
    "factor = 8\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=input_shape),\n",
    "\n",
    "    tf.keras.layers.Dense(units = 125*factor, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "    tf.keras.layers.Dense(units = 75*factor, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=dropout_rate*0.25),\n",
    "\n",
    "    tf.keras.layers.Dense(units = 50*factor, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=dropout_rate*0.25),\n",
    "\n",
    "    tf.keras.layers.Dense(units = 75*factor, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=dropout_rate),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Dense(units = 129*9, activation='relu'),\n",
    "    # tf.keras.layers.Dense((128,9,2), activation='relu'),\n",
    "    # tf.keras.layers.Dense((128,9,2), activation='relu'),\n",
    "    # tf.keras.layers.Dense((128,9,2), activation='relu'),\n",
    "    # tf.keras.layers.Conv2D(3,2, activation='relu', input_shape=input_shape)\n",
    "    tf.keras.layers.Reshape(target_shape=input_shape)\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"mse\",\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70b3b061-1eeb-48bd-b9c8-f2e73f73fa17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 1161)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1000)              1162000   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 600)               600600    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 600)               240600    \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1161)              697761    \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 129, 9)            0         \n",
      "=================================================================\n",
      "Total params: 2,941,361\n",
      "Trainable params: 2,941,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faea64cc-22a7-49a0-8c89-fb11785912cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3135e-06 - val_loss: 2.1860e-05\n",
      "Epoch 2/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3137e-06 - val_loss: 2.1789e-05\n",
      "Epoch 3/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3170e-06 - val_loss: 2.1705e-05\n",
      "Epoch 4/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3103e-06 - val_loss: 2.1718e-05\n",
      "Epoch 5/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3084e-06 - val_loss: 2.1738e-05\n",
      "Epoch 6/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3177e-06 - val_loss: 2.1732e-05\n",
      "Epoch 7/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3194e-06 - val_loss: 2.1801e-05\n",
      "Epoch 8/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3100e-06 - val_loss: 2.1786e-05\n",
      "Epoch 9/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3135e-06 - val_loss: 2.1658e-05\n",
      "Epoch 10/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3027e-06 - val_loss: 2.1661e-05\n",
      "Epoch 11/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3122e-06 - val_loss: 2.1884e-05\n",
      "Epoch 12/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3031e-06 - val_loss: 2.1697e-05\n",
      "Epoch 13/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3096e-06 - val_loss: 2.1676e-05\n",
      "Epoch 14/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3080e-06 - val_loss: 2.1837e-05\n",
      "Epoch 15/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3116e-06 - val_loss: 2.1895e-05\n",
      "Epoch 16/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3019e-06 - val_loss: 2.1772e-05\n",
      "Epoch 17/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3121e-06 - val_loss: 2.1699e-05\n",
      "Epoch 18/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3015e-06 - val_loss: 2.1829e-05\n",
      "Epoch 19/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3160e-06 - val_loss: 2.1779e-05\n",
      "Epoch 20/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3059e-06 - val_loss: 2.1539e-05\n",
      "Epoch 21/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3082e-06 - val_loss: 2.1810e-05\n",
      "Epoch 22/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3042e-06 - val_loss: 2.1631e-05\n",
      "Epoch 23/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.3034e-06 - val_loss: 2.1855e-05\n",
      "Epoch 24/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3015e-06 - val_loss: 2.1736e-05\n",
      "Epoch 25/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3014e-06 - val_loss: 2.1775e-05\n",
      "Epoch 26/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3052e-06 - val_loss: 2.1514e-05\n",
      "Epoch 27/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3037e-06 - val_loss: 2.1871e-05\n",
      "Epoch 28/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3056e-06 - val_loss: 2.1895e-05\n",
      "Epoch 29/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3018e-06 - val_loss: 2.1684e-05\n",
      "Epoch 30/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3017e-06 - val_loss: 2.1872e-05\n",
      "Epoch 31/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3034e-06 - val_loss: 2.1707e-05\n",
      "Epoch 32/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2990e-06 - val_loss: 2.1748e-05\n",
      "Epoch 33/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3008e-06 - val_loss: 2.1696e-05\n",
      "Epoch 34/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2969e-06 - val_loss: 2.1614e-05\n",
      "Epoch 35/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3009e-06 - val_loss: 2.1651e-05\n",
      "Epoch 36/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2981e-06 - val_loss: 2.1792e-05\n",
      "Epoch 37/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2965e-06 - val_loss: 2.1676e-05\n",
      "Epoch 38/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3036e-06 - val_loss: 2.1911e-05\n",
      "Epoch 39/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2942e-06 - val_loss: 2.1554e-05\n",
      "Epoch 40/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3001e-06 - val_loss: 2.1819e-05\n",
      "Epoch 41/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3009e-06 - val_loss: 2.1917e-05\n",
      "Epoch 42/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2987e-06 - val_loss: 2.1858e-05\n",
      "Epoch 43/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2997e-06 - val_loss: 2.1577e-05\n",
      "Epoch 44/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2975e-06 - val_loss: 2.2016e-05\n",
      "Epoch 45/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2922e-06 - val_loss: 2.1562e-05\n",
      "Epoch 46/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2951e-06 - val_loss: 2.1852e-05\n",
      "Epoch 47/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2917e-06 - val_loss: 2.1706e-05\n",
      "Epoch 48/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2975e-06 - val_loss: 2.1545e-05\n",
      "Epoch 49/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3009e-06 - val_loss: 2.1940e-05\n",
      "Epoch 50/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2988e-06 - val_loss: 2.1887e-05\n",
      "Epoch 51/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.3031e-06 - val_loss: 2.1722e-05\n",
      "Epoch 52/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2965e-06 - val_loss: 2.1913e-05\n",
      "Epoch 53/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2970e-06 - val_loss: 2.1666e-05\n",
      "Epoch 54/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2879e-06 - val_loss: 2.1474e-05\n",
      "Epoch 55/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2895e-06 - val_loss: 2.1529e-05\n",
      "Epoch 56/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2973e-06 - val_loss: 2.1507e-05\n",
      "Epoch 57/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2940e-06 - val_loss: 2.1717e-05\n",
      "Epoch 58/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2933e-06 - val_loss: 2.1998e-05\n",
      "Epoch 59/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2965e-06 - val_loss: 2.1583e-05\n",
      "Epoch 60/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2882e-06 - val_loss: 2.1688e-05\n",
      "Epoch 61/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2903e-06 - val_loss: 2.1673e-05\n",
      "Epoch 62/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2885e-06 - val_loss: 2.1754e-05\n",
      "Epoch 63/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2889e-06 - val_loss: 2.1633e-05\n",
      "Epoch 64/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2938e-06 - val_loss: 2.1814e-05\n",
      "Epoch 65/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2940e-06 - val_loss: 2.1697e-05\n",
      "Epoch 66/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2942e-06 - val_loss: 2.1716e-05\n",
      "Epoch 67/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2874e-06 - val_loss: 2.1684e-05\n",
      "Epoch 68/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2929e-06 - val_loss: 2.1964e-05\n",
      "Epoch 69/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2907e-06 - val_loss: 2.1730e-05\n",
      "Epoch 70/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2951e-06 - val_loss: 2.1804e-05\n",
      "Epoch 71/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2935e-06 - val_loss: 2.1751e-05\n",
      "Epoch 72/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2933e-06 - val_loss: 2.1796e-05\n",
      "Epoch 73/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2901e-06 - val_loss: 2.2053e-05\n",
      "Epoch 74/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2873e-06 - val_loss: 2.1631e-05\n",
      "Epoch 75/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2906e-06 - val_loss: 2.1617e-05\n",
      "Epoch 76/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2862e-06 - val_loss: 2.1687e-05\n",
      "Epoch 77/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2858e-06 - val_loss: 2.1749e-05\n",
      "Epoch 78/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2922e-06 - val_loss: 2.1841e-05\n",
      "Epoch 79/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2858e-06 - val_loss: 2.1631e-05\n",
      "Epoch 80/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2916e-06 - val_loss: 2.1589e-05\n",
      "Epoch 81/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2863e-06 - val_loss: 2.1712e-05\n",
      "Epoch 82/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2858e-06 - val_loss: 2.1539e-05\n",
      "Epoch 83/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2865e-06 - val_loss: 2.1806e-05\n",
      "Epoch 84/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2915e-06 - val_loss: 2.1938e-05\n",
      "Epoch 85/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2902e-06 - val_loss: 2.1725e-05\n",
      "Epoch 86/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2868e-06 - val_loss: 2.1613e-05\n",
      "Epoch 87/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2890e-06 - val_loss: 2.2071e-05\n",
      "Epoch 88/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2886e-06 - val_loss: 2.1782e-05\n",
      "Epoch 89/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2897e-06 - val_loss: 2.1560e-05\n",
      "Epoch 90/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2858e-06 - val_loss: 2.1847e-05\n",
      "Epoch 91/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2876e-06 - val_loss: 2.1687e-05\n",
      "Epoch 92/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2899e-06 - val_loss: 2.1824e-05\n",
      "Epoch 93/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2926e-06 - val_loss: 2.1820e-05\n",
      "Epoch 94/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2838e-06 - val_loss: 2.1817e-05\n",
      "Epoch 95/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2876e-06 - val_loss: 2.1835e-05\n",
      "Epoch 96/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2951e-06 - val_loss: 2.1718e-05\n",
      "Epoch 97/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2880e-06 - val_loss: 2.1787e-05\n",
      "Epoch 98/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2888e-06 - val_loss: 2.1581e-05\n",
      "Epoch 99/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2793e-06 - val_loss: 2.1648e-05\n",
      "Epoch 100/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2823e-06 - val_loss: 2.1867e-05\n",
      "Epoch 101/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2862e-06 - val_loss: 2.1791e-05\n",
      "Epoch 102/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2814e-06 - val_loss: 2.1991e-05\n",
      "Epoch 103/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2805e-06 - val_loss: 2.1906e-05\n",
      "Epoch 104/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2785e-06 - val_loss: 2.1713e-05\n",
      "Epoch 105/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2732e-06 - val_loss: 2.1910e-05\n",
      "Epoch 106/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2766e-06 - val_loss: 2.1726e-05\n",
      "Epoch 107/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2883e-06 - val_loss: 2.1765e-05\n",
      "Epoch 108/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2857e-06 - val_loss: 2.1744e-05\n",
      "Epoch 109/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2761e-06 - val_loss: 2.1759e-05\n",
      "Epoch 110/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2836e-06 - val_loss: 2.1999e-05\n",
      "Epoch 111/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2853e-06 - val_loss: 2.2030e-05\n",
      "Epoch 112/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2831e-06 - val_loss: 2.1592e-05\n",
      "Epoch 113/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2792e-06 - val_loss: 2.1793e-05\n",
      "Epoch 114/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2776e-06 - val_loss: 2.1643e-05\n",
      "Epoch 115/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2774e-06 - val_loss: 2.1580e-05\n",
      "Epoch 116/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2790e-06 - val_loss: 2.2038e-05\n",
      "Epoch 117/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2808e-06 - val_loss: 2.1743e-05\n",
      "Epoch 118/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2824e-06 - val_loss: 2.1619e-05\n",
      "Epoch 119/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2814e-06 - val_loss: 2.1817e-05\n",
      "Epoch 120/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2761e-06 - val_loss: 2.1732e-05\n",
      "Epoch 121/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2774e-06 - val_loss: 2.1979e-05\n",
      "Epoch 122/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2805e-06 - val_loss: 2.1756e-05\n",
      "Epoch 123/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2775e-06 - val_loss: 2.1723e-05\n",
      "Epoch 124/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2814e-06 - val_loss: 2.1760e-05\n",
      "Epoch 125/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2782e-06 - val_loss: 2.1998e-05\n",
      "Epoch 126/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2744e-06 - val_loss: 2.1581e-05\n",
      "Epoch 127/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2809e-06 - val_loss: 2.1552e-05\n",
      "Epoch 128/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2749e-06 - val_loss: 2.1765e-05\n",
      "Epoch 129/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2783e-06 - val_loss: 2.1678e-05\n",
      "Epoch 130/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2823e-06 - val_loss: 2.1564e-05\n",
      "Epoch 131/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2754e-06 - val_loss: 2.1792e-05\n",
      "Epoch 132/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2751e-06 - val_loss: 2.1922e-05\n",
      "Epoch 133/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2803e-06 - val_loss: 2.1763e-05\n",
      "Epoch 134/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2760e-06 - val_loss: 2.1867e-05\n",
      "Epoch 135/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2796e-06 - val_loss: 2.1762e-05\n",
      "Epoch 136/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2746e-06 - val_loss: 2.1777e-05\n",
      "Epoch 137/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2706e-06 - val_loss: 2.1715e-05\n",
      "Epoch 138/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2750e-06 - val_loss: 2.1815e-05\n",
      "Epoch 139/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2728e-06 - val_loss: 2.1724e-05\n",
      "Epoch 140/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2747e-06 - val_loss: 2.1872e-05\n",
      "Epoch 141/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2734e-06 - val_loss: 2.1647e-05\n",
      "Epoch 142/200\n",
      "842/842 [==============================] - 12s 15ms/step - loss: 4.2786e-06 - val_loss: 2.1800e-05\n",
      "Epoch 143/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2708e-06 - val_loss: 2.1776e-05\n",
      "Epoch 144/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2707e-06 - val_loss: 2.1921e-05\n",
      "Epoch 145/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2691e-06 - val_loss: 2.1794e-05\n",
      "Epoch 146/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2735e-06 - val_loss: 2.1970e-05\n",
      "Epoch 147/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2757e-06 - val_loss: 2.1808e-05\n",
      "Epoch 148/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2687e-06 - val_loss: 2.1728e-05\n",
      "Epoch 149/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2708e-06 - val_loss: 2.1798e-05\n",
      "Epoch 150/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2682e-06 - val_loss: 2.1878e-05\n",
      "Epoch 151/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2716e-06 - val_loss: 2.1784e-05\n",
      "Epoch 152/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2701e-06 - val_loss: 2.1694e-05\n",
      "Epoch 153/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2706e-06 - val_loss: 2.1774e-05\n",
      "Epoch 154/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2697e-06 - val_loss: 2.1918e-05\n",
      "Epoch 155/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2686e-06 - val_loss: 2.1800e-05\n",
      "Epoch 156/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2702e-06 - val_loss: 2.1785e-05\n",
      "Epoch 157/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2699e-06 - val_loss: 2.1796e-05\n",
      "Epoch 158/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2636e-06 - val_loss: 2.1862e-05\n",
      "Epoch 159/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2688e-06 - val_loss: 2.1926e-05\n",
      "Epoch 160/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2730e-06 - val_loss: 2.1805e-05\n",
      "Epoch 161/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2692e-06 - val_loss: 2.1762e-05\n",
      "Epoch 162/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2716e-06 - val_loss: 2.1784e-05\n",
      "Epoch 163/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2665e-06 - val_loss: 2.1816e-05\n",
      "Epoch 164/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2726e-06 - val_loss: 2.1831e-05\n",
      "Epoch 165/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2712e-06 - val_loss: 2.2005e-05\n",
      "Epoch 166/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2643e-06 - val_loss: 2.1737e-05\n",
      "Epoch 167/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2630e-06 - val_loss: 2.1815e-05\n",
      "Epoch 168/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2731e-06 - val_loss: 2.1718e-05\n",
      "Epoch 169/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2706e-06 - val_loss: 2.1897e-05\n",
      "Epoch 170/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2651e-06 - val_loss: 2.1686e-05\n",
      "Epoch 171/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2685e-06 - val_loss: 2.1749e-05\n",
      "Epoch 172/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2652e-06 - val_loss: 2.1797e-05\n",
      "Epoch 173/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2624e-06 - val_loss: 2.1698e-05\n",
      "Epoch 174/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2652e-06 - val_loss: 2.1811e-05\n",
      "Epoch 175/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2642e-06 - val_loss: 2.1662e-05\n",
      "Epoch 176/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2675e-06 - val_loss: 2.1723e-05\n",
      "Epoch 177/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2656e-06 - val_loss: 2.1688e-05\n",
      "Epoch 178/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2632e-06 - val_loss: 2.1725e-05\n",
      "Epoch 179/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2639e-06 - val_loss: 2.1857e-05\n",
      "Epoch 180/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2688e-06 - val_loss: 2.1953e-05\n",
      "Epoch 181/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2642e-06 - val_loss: 2.1762e-05\n",
      "Epoch 182/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2702e-06 - val_loss: 2.1699e-05\n",
      "Epoch 183/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2643e-06 - val_loss: 2.1891e-05\n",
      "Epoch 184/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2618e-06 - val_loss: 2.1678e-05\n",
      "Epoch 185/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2638e-06 - val_loss: 2.1780e-05\n",
      "Epoch 186/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2646e-06 - val_loss: 2.1702e-05\n",
      "Epoch 187/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2617e-06 - val_loss: 2.1743e-05\n",
      "Epoch 188/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2678e-06 - val_loss: 2.1915e-05\n",
      "Epoch 189/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2660e-06 - val_loss: 2.1799e-05\n",
      "Epoch 190/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2602e-06 - val_loss: 2.1718e-05\n",
      "Epoch 191/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2670e-06 - val_loss: 2.1800e-05\n",
      "Epoch 192/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2721e-06 - val_loss: 2.1673e-05\n",
      "Epoch 193/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2659e-06 - val_loss: 2.2133e-05\n",
      "Epoch 194/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2629e-06 - val_loss: 2.1669e-05\n",
      "Epoch 195/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2595e-06 - val_loss: 2.1808e-05\n",
      "Epoch 196/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2676e-06 - val_loss: 2.1622e-05\n",
      "Epoch 197/200\n",
      "842/842 [==============================] - 11s 14ms/step - loss: 4.2657e-06 - val_loss: 2.1848e-05\n",
      "Epoch 198/200\n",
      "842/842 [==============================] - 11s 13ms/step - loss: 4.2641e-06 - val_loss: 2.2002e-05\n",
      "Epoch 199/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2597e-06 - val_loss: 2.1693e-05\n",
      "Epoch 200/200\n",
      "842/842 [==============================] - 12s 14ms/step - loss: 4.2643e-06 - val_loss: 2.1755e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7faed075b790>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,validation_data=test_dataset, epochs=200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239637b6-6a81-4fa3-bbf4-ced84367c9a7",
   "metadata": {},
   "source": [
    "## Looking at predictions\n",
    "Inspecting the predictions of the model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6cfc8fa7-73bd-45b1-8f7e-6ee37ac0b6ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(examples[:10000,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48bd0bde-d606-4d18-b9b2-d42e58222c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00011937795"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd593580-d69e-4a59-97cc-11df9147c5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.shape\n",
    "\n",
    "def plot_example(index):\n",
    "    prediction = predictions[index]\n",
    "    actual = labels[index]\n",
    "    noisy = examples[index]\n",
    "    \n",
    "    fig, [ax1, ax2, ax3, ax4] = plt.subplots(1,4)\n",
    "    ax2.imshow(prediction, aspect = \"auto\")\n",
    "    ax3.imshow(actual, aspect= \"auto\")\n",
    "    ax1.imshow(noisy, aspect=\"auto\")\n",
    "    ax4.imshow(actual-prediction, aspect=\"auto\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f92e3b7-3df9-483f-ad3b-03fc0651862f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea73407db2444b0acf49ef71f1518fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='index', max=9999), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_example(index)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_example, index=(0, 9999, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f059822-d8d3-42c1-acbd-5d6dfcd5361b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_time_domain( index):\n",
    "\n",
    "    test_noisy = noisy_stft.get_data()[index,:,:,0]\n",
    "    test_noisy_phase = noisy_stft.get_data()[index,:,:,1]\n",
    "\n",
    "    test_pure = labels[index,:,:]\n",
    "    test_pure_phase = noisy_stft.get_data()[index,:,:,1]\n",
    "\n",
    "    model_amp = predictions[index]\n",
    "    noisy_phase = noisy_stft.get_data()[index,:,:,1]\n",
    "\n",
    "    fig, [ax1, ax2] =plt.subplots(1,2)\n",
    "    t, signal_pure = istft(test_pure*np.exp(1j*test_pure_phase), fs = 1./5.)\n",
    "    t, signal_model = istft(model_amp*np.exp(1j*noisy_phase), fs = 1./5.)\n",
    "    t, signal_example = istft(test_noisy*np.exp(1j*test_noisy_phase), fs = 1./5.)\n",
    "\n",
    "    fig.set_size_inches((12,10))\n",
    "    ax1.plot(t,signal_example)\n",
    "    ax2.plot(t, signal_model)\n",
    "    ax2.plot(t, signal_pure, alpha=0.5, color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbfa7920-0fbe-4288-8bd6-29c1745aa863",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce99069ee0cf49d6aeb47f4a99d82b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='index', max=9999), Output()), _dom_classes=('widget-i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_time_domain(index)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_time_domain, index = (0,9999,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e00c5-f9df-4420-9a6f-1e21ba5fdcf8",
   "metadata": {},
   "source": [
    "## Visualize the effect on the test set\n",
    "Previous visualizations were for the training set only.\n",
    "\n",
    "Check the influence of the test set here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b78f1f78-755e-4437-a802-c9c24c9c5907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_test = model.predict(examples_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "da7c1e6d-5910-41a5-9ed1-cf7d3294b509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples_test = noisy_test_stft.get_data()[::stride_reduce,:,:,0]\n",
    "labels_test = pure_test_stft.get_data()[::stride_reduce,:,:,0]\n",
    "\n",
    "examples_test_phase = noisy_test_stft.get_data()[::stride_reduce,:,:,1]\n",
    "labels_test_phase = pure_test_stft.get_data()[::stride_reduce,:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bea6eb91-1f76-4d1d-baac-095078068c73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_time_domain_test( index):\n",
    "\n",
    "    # get the test set prediction\n",
    "    test_noisy = examples_test[index]\n",
    "    test_noisy_phase = examples_test_phase[index]\n",
    "    \n",
    "    # the pure example from the test set\n",
    "    test_pure = labels_test[index]\n",
    "    test_pure_phase = labels_test_phase[index]\n",
    "\n",
    "    model_amp = predictions_test[index]\n",
    "    noisy_phase = examples_test_phase[index]\n",
    "    \n",
    "    fig, [ax1, ax2] =plt.subplots(1,2)\n",
    "    t, signal_pure = istft(test_pure*np.exp(1j*test_pure_phase), fs = 1./5.)\n",
    "    t, signal_model = istft(model_amp*np.exp(1j*noisy_phase), fs = 1./5.)\n",
    "    t, signal_example = istft(test_noisy*np.exp(1j*test_noisy_phase), fs = 1./5.)\n",
    "\n",
    "    fig.set_size_inches((12,10))\n",
    "    ax1.plot(t,signal_example)\n",
    "    ax2.plot(t, signal_model)\n",
    "    ax2.plot(t, signal_pure, alpha=0.5, color=\"red\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4a87db6-d0c5-42d4-bae6-2fb777e89953",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a89122bd9a42e1b0794f1391a4417a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=500, description='index', max=1000), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_time_domain_test(index)>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(plot_time_domain_test, index = (0,1000,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762b93b-6e11-44ec-a3c5-b1adfa2fb528",
   "metadata": {},
   "source": [
    "## Store the model\n",
    "Storing the model after a long training session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "57c882d1-4477-4896-924c-b5177c0f523b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_folder = \"model/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ec72095-e8de-44e2-9b31-1d55d04a3461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get the current date\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "# Format the date as \"day-month-year\"\n",
    "date_str = now.strftime(\"%d-%m-h%H%M\")\n",
    "\n",
    "# \n",
    "\n",
    "# Parameter count\n",
    "trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "\n",
    "\n",
    "model_name = f\"model-{date_str}-p{trainableParams}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6bfa107d-16e1-4b79-b822-b71887e34bda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/model-29-03-h1401-p2941361/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = model_folder + model_name\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ab5e2-119a-4c76-ab9e-528b84411957",
   "metadata": {},
   "source": [
    "## Analysis of maximum values\n",
    "Looking at maximum values of amplitude over the whole array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2751a123-aa1d-4437-8104-c6b789bf440e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_example = noisy_stft.get_data()[0]\n",
    "shape = test_example.shape\n",
    "test_example_reshaped = noisy_stft.get_data()[0].reshape((1, shape[0], shape[1], shape[2]))\n",
    "\n",
    "test_pure = pure_stft.get_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "993ba3f6-b802-4d2b-ac0c-35f843092729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1167289817731223"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pure[:,:,0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8bffc-c85c-4356-9fe1-386ff9c0351c",
   "metadata": {},
   "source": [
    "Todo\n",
    "Normalize the phase and amplitude values.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "728854d5-4030-48e9-8865-89228857d160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amps_noisy =noisy_stft.get_data()[:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0e735a-37b3-4780-a56d-6f0e6b212830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amps_noisy_flattened = amps_noisy.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b516141-c7d1-4207-a12f-a0031fb15379",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.0101877e+07, 1.1225070e+06, 1.9600700e+05, 1.0042300e+05,\n",
       "        5.1438000e+04, 2.1964000e+04, 9.8380000e+03, 4.6260000e+03,\n",
       "        1.1690000e+03, 1.5100000e+02]),\n",
       " array([2.14359953e-11, 1.67539747e-02, 3.35079495e-02, 5.02619242e-02,\n",
       "        6.70158989e-02, 8.37698737e-02, 1.00523848e-01, 1.17277823e-01,\n",
       "        1.34031798e-01, 1.50785773e-01, 1.67539747e-01]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(amps_noisy_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9063e8e5-df9b-4911-90b9-2606ef41e874",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "amps_noisy_max = amps_noisy.max(axis=2).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d7f8f9f-fe81-4599-b965-31be2a86179d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amps_noisy_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50c79a4d-7dbc-41a4-aa77-fc877d1d6468",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 153.,  364., 2132., 2197., 1479., 1392., 1000.,  879.,  345.,\n",
       "          59.]),\n",
       " array([0.04645806, 0.05856623, 0.0706744 , 0.08278256, 0.09489073,\n",
       "        0.1069989 , 0.11910707, 0.13121524, 0.14332341, 0.15543158,\n",
       "        0.16753975]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(amps_noisy_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb57de-866e-4108-8e5c-98068a5f6c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32d850-cfda-4b0b-87c4-0582e2b3116c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
